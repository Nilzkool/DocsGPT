---
title: DocsGPT Settings
description: Configure your DocsGPT application by understanding the basic settings.
---

# DocsGPT Settings

DocsGPT is highly configurable, allowing you to tailor it to your specific needs and preferences. You can control various aspects of the application, from choosing the Large Language Model (LLM) provider to selecting embedding models and vector stores.

This document will guide you through the basic settings you can configure in DocsGPT. These settings determine how DocsGPT interacts with LLMs and processes your data.

## Configuration Methods

There are two primary ways to configure DocsGPT settings:

### 1. Configuration via `.env` file (Recommended)

The easiest and recommended way to configure basic settings is by using a `.env` file. This file should be located in the **root directory** of your DocsGPT project.

**Example `.env` file structure:**

```
LLM_PROVIDER=openai
API_KEY=YOUR_OPENAI_API_KEY
LLM_NAME=gpt-4o
```

### 2. Configuration via `settings.py` file (Advanced)

For more advanced configurations or if you prefer to manage settings directly in code, you can modify the `settings.py` file. This file is located in the `application/core` directory of your DocsGPT project.

While modifying `settings.py` offers more flexibility, it's generally recommended to use the `.env` file for basic settings and reserve `settings.py` for more complex adjustments or when you need to configure settings programmatically.

**Location of `settings.py`:** `application/core/settings.py`

## Basic Settings Explained

Here are some of the most fundamental settings you'll likely want to configure:

- **`LLM_PROVIDER`**: This setting determines which Large Language Model (LLM) provider DocsGPT will use. It tells DocsGPT which API to interact with.

    - **Common values:**
        - `docsgpt`: Use the DocsGPT Public API Endpoint (simple and free).
        - `openai`: Use OpenAI's API (requires an API key).
        - `google`: Use Google's Vertex AI or Gemini models.
        - `anthropic`: Use Anthropic's Claude models.
        - `groq`: Use Groq's models.
        - `huggingface`: Use HuggingFace Inference API.
        - `azure_openai`: Use Azure OpenAI Service.
        - `openai` (when using local inference engines like Ollama): This signals DocsGPT to use an OpenAI-compatible API format, even if the actual LLM is running locally.

- **`LLM_NAME`**: Specifies the specific model to use from the chosen LLM provider. The available models depend on the `LLM_PROVIDER` you've selected.

    - **Examples:**
        - For `LLM_PROVIDER=openai`: `gpt-4o`
        - For `LLM_PROVIDER=google`: `gemini-2.0-flash`
        - For local models (e.g., Ollama): `llama3.2:1b`

- **`EMBEDDINGS_NAME`**: This setting defines which embedding model DocsGPT will use to generate vector embeddings for your documents. Embeddings are numerical representations of text that allow DocsGPT to understand the semantic meaning of your documents for efficient search and retrieval.

    - **Default value:** `huggingface_sentence-transformers/all-mpnet-base-v2`.

- **`API_KEY`**: Required for most cloud-based LLM providers. This is your authentication key to access the LLM provider's API.

- **`OPENAI_BASE_URL`**: Specifically used when `LLM_PROVIDER` is set to `openai` but you are connecting to a local inference engine that exposes an OpenAI-compatible API. This setting tells DocsGPT where to find your local LLM server.

## Configuration Examples

Let's look at some concrete examples of how to configure these settings in your `.env` file.

### Example for Cloud API Provider (OpenAI)

```
LLM_PROVIDER=openai
API_KEY=YOUR_OPENAI_API_KEY  # Replace with your actual OpenAI API key
LLM_NAME=gpt-4o
```

### Example for Local Deployment

```
LLM_PROVIDER=openai # Using OpenAI compatible API format for local models
API_KEY=
LLM_NAME=llama3.2:1b
OPENAI_BASE_URL=http://host.docker.internal:11434/v1
EMBEDDINGS_NAME=huggingface_sentence-transformers/all-mpnet-base-v2
```

## Authentication Settings

DocsGPT includes a JWT-based authentication feature for managing sessions or securing local deployments while allowing access.

- **`AUTH_TYPE`**: Determines the authentication method.
    - Possible values: `None`, `simple_jwt`, `session_jwt`.
- **`JWT_SECRET_KEY`**: Secret key used to sign and verify JWTs. If not provided, DocsGPT will generate and store one in `.jwt_secret_key`.

For details on how authentication works and how to configure it, see the [Application App Code](https://github.com/Nilzkool/DocsGPT/blob/main/application/app.py).

## Exploring More Settings

For a complete list of available settings and their descriptions, refer to `application/core/settings.py` in the repository root.