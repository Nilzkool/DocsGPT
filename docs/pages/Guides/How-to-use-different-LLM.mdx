---
title: Setting Up Different LLMs
description: Learn how to configure and switch between various language models including the new NovitaLLM.
---

import { Callout } from 'nextra/components'
import Image from 'next/image'
import { Steps } from 'nextra/components'

# Setting Up Local Language Models for Your App

Setting up local language models for your app can significantly enhance its capabilities, enabling it to understand and generate text in multiple languages without relying solely on external APIs. By integrating both cloud-based and open-source models, you can improve privacy, reduce latency, and ensure continuous functionality even in offline environments. Here's a comprehensive guide on how to set up different language models for your application:

## Steps:
### For cloud version LLM change:
<Steps>
### Step 1
Visit the chat screen and notice the default LLM that is selected.
### Step 2
Click on the LLM selector to view the dropdown containing the available language models.
### Step 3
Choose the LLM of your choice. Options include popular providers such as OpenAI, Azure OpenAI, Anthropic, Groq, Google, and now NovitaLLM, powered by Novita (https://api.novita.ai).
</Steps>

*Note:* If you wish to use NovitaLLM, it is available from the same dropdown and works similarly to the other cloud providers.

### Video Demo
<Image src="/llms.gif" alt="LLM selection demo" width={800} height={500} />

### For Open source llm change:
<Steps>
### Step 1
For the open source version, please edit the environment variables such as `LLM_PROVIDER`, `LLM_NAME`, and others in the .env file. Refer to [‚öôÔ∏è App Configuration](/Deploying/DocsGPT-Settings) for more details.
### Step 2
Visit [‚òÅÔ∏è Cloud Providers](/Models/cloud-providers) for the updated list of online models. Ensure you have the correct API_KEY and LLM_PROVIDER set. For self-hosted setups, please visit [üñ•Ô∏è Local Inference](/Models/local-inference).
</Steps>
